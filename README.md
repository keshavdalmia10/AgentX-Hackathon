# AgentX: Multi-Dialect SQL Evaluation Framework

> A comprehensive evaluation framework for LLM-powered SQL agents with multi-dialect support, hallucination detection, and multi-dimensional scoring.

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Python 3.10+](https://img.shields.io/badge/python-3.10+-blue.svg)](https://www.python.org/downloads/)

---

## Overview

AgentX evaluates SQL queries generated by LLM agents across multiple database dialects. It provides:

- **Multi-Dialect Support**: SQLite, DuckDB, PostgreSQL, BigQuery, Snowflake
- **Hallucination Detection**: Identifies phantom tables, columns, and functions before execution
- **Enhanced Scoring**: 7-dimensional scoring with adaptive thresholds
- **Dialect-Aware Validation**: Validates SQL syntax and functions per dialect

---

## Architecture

```
┌─────────────────────────────────────────────────────────────────────────────┐
│                          AGENTX EVALUATION SYSTEM                           │
├─────────────────────────────────────────────────────────────────────────────┤
│                                                                             │
│  ┌──────────────────────────────────────────────────────────────────────┐  │
│  │                         SQL EXECUTOR                                  │  │
│  │  ┌─────────────┐  ┌─────────────┐  ┌─────────────┐  ┌─────────────┐  │  │
│  │  │   SQLite    │  │   DuckDB    │  │ PostgreSQL  │  │  BigQuery   │  │  │
│  │  │  (default)  │  │ (analytics) │  │   (prod)    │  │  (cloud)    │  │  │
│  │  └─────────────┘  └─────────────┘  └─────────────┘  └─────────────┘  │  │
│  └──────────────────────────────────────────────────────────────────────┘  │
│                                    │                                        │
│                                    ▼                                        │
│  ┌──────────────────────────────────────────────────────────────────────┐  │
│  │                      VALIDATION LAYER                                 │  │
│  │  ┌─────────────────┐  ┌─────────────────┐  ┌─────────────────────┐   │  │
│  │  │ SQL Parser      │  │ Hallucination   │  │ Schema Validator    │   │  │
│  │  │ • sqlglot AST   │  │ Detector        │  │ • Table existence   │   │  │
│  │  │ • Multi-dialect │  │ • Phantom tables│  │ • Column validation │   │  │
│  │  │ • Transpilation │  │ • Phantom cols  │  │ • Type checking     │   │  │
│  │  └─────────────────┘  │ • Invalid funcs │  └─────────────────────┘   │  │
│  │                       └─────────────────┘                             │  │
│  └──────────────────────────────────────────────────────────────────────┘  │
│                                    │                                        │
│                                    ▼                                        │
│  ┌──────────────────────────────────────────────────────────────────────┐  │
│  │                       SCORING ENGINE                                  │  │
│  │  ┌─────────────┐  ┌─────────────┐  ┌─────────────┐  ┌─────────────┐  │  │
│  │  │ Correctness │  │ Efficiency  │  │   Safety    │  │  Semantic   │  │  │
│  │  │    35%      │  │    15%      │  │    20%      │  │  Accuracy   │  │  │
│  │  │             │  │  Adaptive   │  │  Weighted   │  │    10%      │  │  │
│  │  └─────────────┘  │ Thresholds  │  │ Hallucin.   │  └─────────────┘  │  │
│  │                   └─────────────┘  └─────────────┘                    │  │
│  │  ┌─────────────┐  ┌─────────────┐  ┌─────────────┐                    │  │
│  │  │Completeness │  │    Best     │  │    Plan     │                    │  │
│  │  │    10%      │  │  Practices  │  │  Quality    │                    │  │
│  │  │             │  │     5%      │  │     5%      │                    │  │
│  │  └─────────────┘  └─────────────┘  └─────────────┘                    │  │
│  └──────────────────────────────────────────────────────────────────────┘  │
│                                                                             │
└─────────────────────────────────────────────────────────────────────────────┘
```

---

## Quick Start

### Installation

```bash
# Clone repository
git clone https://github.com/ashcastelinocs124/AgentX-Hackathon.git
cd AgentX-Hackathon

# Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt
```

### Basic Usage

```python
from agentx import SQLExecutor, ExecutorConfig

# SQLite (zero setup, in-memory)
executor = SQLExecutor(ExecutorConfig(dialect="sqlite"))

# Execute and evaluate a query
result = executor.process_query("SELECT 1 + 1 as answer")
print(f"Status: {result.overall_status}")  # SUCCESS or FAILED
print(f"Data: {result.data}")              # [{'answer': 2}]

executor.close()
```

### Run Evaluation Pipeline

```bash
# SQLite (default)
python run_evaluation_pipeline.py "SELECT * FROM users WHERE age > 25"

# DuckDB
python run_evaluation_pipeline.py "SELECT * FROM users" --dialect duckdb

# PostgreSQL
python run_evaluation_pipeline.py "SELECT * FROM users" \
    --dialect postgresql \
    --connection-string "postgresql://user:pass@localhost/db"

# With expected results for comparison
python run_evaluation_pipeline.py --file query.sql --expected expected.json
```

### Run Tests

```bash
# Test multi-dialect support
python test_multi_dialect.py

# Test enhanced scoring
python test_enhanced_scoring.py

# Test evaluation pipeline integration
python test_evaluation_pipeline.py

# Test A2A protocol interface
python test_a2a.py
```

---

## Supported Dialects

| Dialect | Status | Setup Required | Use Case |
|---------|--------|----------------|----------|
| **SQLite** | Default | None | Testing, development, small datasets |
| **DuckDB** | Supported | `pip install duckdb` | Analytics, columnar workloads |
| **PostgreSQL** | Supported | Connection string | Production databases |
| **BigQuery** | Supported | GCP credentials | Cloud data warehouses |
| **Snowflake** | Planned | - | Enterprise data warehouses |
| **MySQL** | Planned | - | Web applications |

---

## Scoring Dimensions

### Enhanced Scorer (7 Dimensions)

| Dimension | Weight | Description |
|-----------|--------|-------------|
| **Correctness** | 35% | Result matches expected output |
| **Efficiency** | 15% | Query execution time (adaptive thresholds) |
| **Safety** | 20% | Validation + weighted hallucination severity |
| **Completeness** | 10% | Result quality (nulls, truncation) |
| **Semantic Accuracy** | 10% | Value-level comparison beyond row counts |
| **Best Practices** | 5% | SQL code quality (no SELECT *, proper JOINs) |
| **Plan Quality** | 5% | Execution plan analysis (index usage) |

### Scoring Presets

```python
from evaluation.enhanced_scorer import create_enhanced_scorer

# Balanced scoring (default)
scorer = create_enhanced_scorer("default")

# Higher weight on correctness and safety
scorer = create_enhanced_scorer("strict")

# Higher weight on efficiency and plan quality
scorer = create_enhanced_scorer("performance")

# Higher weight on best practices
scorer = create_enhanced_scorer("quality")
```

---

## Key Features

### 1. Hallucination Detection

Detects phantom identifiers **before** execution:

```python
from agentx import HallucinationDetector, create_adapter

# Create schema snapshot
adapter = create_adapter("sqlite")
adapter.connect()
adapter.execute("CREATE TABLE users (id INT, name TEXT)")
schema = adapter.get_schema_snapshot()

# Detect hallucinations
detector = HallucinationDetector(dialect="sqlite")
report = detector.detect("SELECT fake_column FROM users", schema)

print(report.phantom_columns)  # ['fake_column']
print(report.hallucination_score)  # 0.5
```

### 2. Query Complexity Analysis

Adaptive expectations based on query complexity:

```python
from evaluation.advanced_scoring import QueryComplexityAnalyzer

analyzer = QueryComplexityAnalyzer()

# Simple query
report = analyzer.analyze("SELECT name FROM users WHERE id = 1")
print(report.complexity_level)  # "simple"

# Complex query
report = analyzer.analyze("""
    WITH monthly AS (SELECT user_id, SUM(amount) FROM orders GROUP BY 1)
    SELECT u.name, m.total, ROW_NUMBER() OVER (ORDER BY m.total)
    FROM users u JOIN monthly m ON u.id = m.user_id
""")
print(report.complexity_level)  # "complex" or "very_complex"
```

### 3. Dialect-Aware Validation

Validates functions per dialect:

```python
from agentx import MultiDialectSQLParser

parser = MultiDialectSQLParser()

# SAFE_DIVIDE is BigQuery-specific
invalid = parser.validate_functions(
    "SELECT SAFE_DIVIDE(a, b) FROM table1",
    dialect="sqlite"
)
print(invalid)  # ['SAFE_DIVIDE']

# Valid for BigQuery
invalid = parser.validate_functions(
    "SELECT SAFE_DIVIDE(a, b) FROM table1",
    dialect="bigquery"
)
print(invalid)  # []
```

### 4. Result Comparison

Flexible comparison with tolerance:

```python
from evaluation.result_comparator import DefaultResultComparator

comparator = DefaultResultComparator(
    numeric_tolerance=1e-6,
    ignore_row_order=True,
    case_sensitive=False,
)

result = comparator.compare(actual_results, expected_results)
print(f"Match: {result.is_match}")
print(f"Score: {result.match_score}")
```

---

## A2A Protocol Interface

AgentX provides a standardized A2A (Agent-to-Agent) REST API for external agents to interact with the benchmark.

### Start the A2A Server

```bash
# Start with default settings (SQLite, port 5000)
python -m a2a.server

# Custom configuration
python -m a2a.server --dialect postgresql --port 8080 --host 0.0.0.0
```

### API Endpoints

| Method | Endpoint | Description |
|--------|----------|-------------|
| `GET` | `/info` | Get benchmark information |
| `GET` | `/health` | Health check |
| `GET` | `/schema` | Get database schema |
| `POST` | `/agents/register` | Register an agent |
| `POST` | `/tasks` | Get available evaluation tasks |
| `POST` | `/evaluate` | Submit SQL for evaluation |
| `POST` | `/evaluate/batch` | Batch evaluation |
| `GET` | `/leaderboard` | View leaderboard |
| `GET` | `/agents/{id}/results` | Get agent results |

### Agent Integration Example

```python
from a2a import A2AClient

# Connect to benchmark server
client = A2AClient("http://localhost:5000")

# Register your agent
agent = client.register(
    agent_name="MyLLMAgent",
    agent_version="1.0.0",
    capabilities=["sql_generation", "schema_understanding"],
)

# Get available tasks
tasks = client.get_tasks(difficulty="easy", limit=5)

# Submit SQL for evaluation
for task in tasks:
    sql = my_llm_generate_sql(task.question, task.schema_info)  # Your agent
    result = client.evaluate(task.task_id, sql)

    print(f"Task: {task.task_id}")
    print(f"Score: {result.scores.overall:.2%}")
    print(f"Correctness: {result.scores.correctness:.2%}")
    print(f"Safety: {result.scores.safety:.2%}")

# Check your ranking
leaderboard = client.get_leaderboard()
```

### Evaluation Request Format

```json
{
    "agent_id": "your-agent-id",
    "task_id": "sqlite_simple_select",
    "sql": "SELECT * FROM customers LIMIT 10",
    "execution_trace": [
        {"step": 1, "action": "analyze_schema"},
        {"step": 2, "action": "generate_sql"}
    ]
}
```

### Evaluation Response Format

```json
{
    "task_id": "sqlite_simple_select",
    "status": "success",
    "scores": {
        "overall": 0.95,
        "correctness": 1.0,
        "efficiency": 0.9,
        "safety": 1.0,
        "completeness": 0.9,
        "semantic_accuracy": 1.0,
        "best_practices": 0.85,
        "plan_quality": 0.95
    },
    "execution_success": true,
    "rows_returned": 10,
    "execution_time_ms": 2.5,
    "suggestions": ["Specify only the columns you need"]
}
```

---

## Project Structure

```
AgentX-Hackathon/
├── src/agentx/                    # Core evaluation library
│   ├── __init__.py                # Public API exports
│   ├── dialects/                  # Dialect configurations
│   │   └── registry.py            # SQLite, DuckDB, PostgreSQL, BigQuery configs
│   ├── executor/                  # SQL execution
│   │   └── sql_executor.py        # Multi-dialect executor
│   ├── infrastructure/            # Database adapters
│   │   ├── database.py            # SQLite, DuckDB, PostgreSQL adapters
│   │   └── models.py              # Schema models (TableInfo, ColumnInfo)
│   └── validation/                # SQL validation
│       ├── sql_parser.py          # Multi-dialect parser (sqlglot)
│       └── hallucination.py       # Hallucination detection
│
├── a2a/                           # A2A Protocol Interface
│   ├── __init__.py                # Public exports
│   ├── server.py                  # REST API server (Flask)
│   ├── client.py                  # Client library for agents
│   └── models.py                  # Request/response models
│
├── evaluation/                    # Scoring system
│   ├── data_structures.py         # ExecutionResult, ComparisonResult
│   ├── result_comparator.py       # Result comparison logic
│   ├── scorer.py                  # Basic 4-dimension scorer
│   ├── advanced_scoring.py        # Advanced scoring components
│   └── enhanced_scorer.py         # 7-dimension enhanced scorer
│
├── run_evaluation_pipeline.py     # CLI entry point
├── requirements.txt               # Dependencies
│
├── test_multi_dialect.py          # Multi-dialect tests
├── test_enhanced_scoring.py       # Scoring component tests
├── test_evaluation_pipeline.py    # Integration tests
└── test_a2a.py                    # A2A interface tests
```

---

## API Reference

### SQLExecutor

```python
from agentx import SQLExecutor, ExecutorConfig

# Configuration
config = ExecutorConfig(
    dialect="sqlite",           # sqlite, duckdb, postgresql, bigquery
    db_path=":memory:",         # For file-based DBs
    connection_string=None,     # For PostgreSQL
    row_limit=1000,             # Max rows to return
    timeout_seconds=30.0,       # Query timeout
    validate_before_execute=True,  # Enable hallucination detection
)

# Create executor
executor = SQLExecutor(config)

# Process query (validate -> execute -> analyze)
result = executor.process_query(sql, verbose=True)

# Access results
result.overall_status      # "SUCCESS" or "FAILED"
result.data                # List of row dicts
result.validation          # Validation details
result.execution           # Execution details
result.analysis            # Analysis insights

executor.close()
```

### EnhancedScorer

```python
from evaluation.enhanced_scorer import EnhancedScorer
from evaluation.data_structures import ComparisonResult, ExecutionResult

scorer = EnhancedScorer()

score = scorer.score(
    comparison=comparison_result,
    execution_result=execution_result,
    sql="SELECT ...",           # For complexity analysis
    dialect="sqlite",           # For adaptive thresholds
    expected_results=[...],     # For semantic accuracy
    plan_text="...",            # For plan analysis
)

# Access scores
score.overall               # 0.0 - 1.0
score.correctness           # 0.0 - 1.0
score.efficiency            # 0.0 - 1.0
score.safety                # 0.0 - 1.0
score.semantic_accuracy_score
score.best_practices_score
score.plan_quality_score

# Detailed analysis
score.complexity_report     # Query complexity breakdown
score.hallucination_details # Hallucination penalties
score.error_analysis        # Error classification
```

---

## Configuration

### Environment Variables

```bash
# PostgreSQL
export AGENTX_PG_HOST=localhost
export AGENTX_PG_PORT=5432
export AGENTX_PG_USER=user
export AGENTX_PG_PASSWORD=password
export AGENTX_PG_DATABASE=testdb

# BigQuery
export GOOGLE_APPLICATION_CREDENTIALS=/path/to/credentials.json
export AGENTX_BQ_PROJECT=my-project
export AGENTX_BQ_DATASET=my_dataset
```

### Docker Compose (PostgreSQL)

```bash
docker-compose up -d
```

This starts PostgreSQL on `localhost:5432` with:
- User: `testuser`
- Password: `testpass`
- Database: `testdb`

---

## Examples

### Example 1: Evaluate Query with Expected Results

```python
import sys
sys.path.insert(0, 'src')

from agentx import SQLExecutor, ExecutorConfig
from evaluation.enhanced_scorer import EnhancedScorer
from evaluation.result_comparator import DefaultResultComparator
from evaluation.data_structures import AgentResult

# Setup
executor = SQLExecutor(ExecutorConfig(dialect="sqlite"))
executor.adapter.execute("CREATE TABLE users (id INT, name TEXT, age INT)")
executor.adapter.execute("INSERT INTO users VALUES (1, 'Alice', 30), (2, 'Bob', 25)")
executor.refresh_schema()

# Execute query
result = executor.process_query("SELECT name, age FROM users WHERE age > 26")

# Compare with expected
expected = [{"name": "Alice", "age": 30}]
comparator = DefaultResultComparator()
comparison = comparator.compare(result.data, expected)

# Score
scorer = EnhancedScorer()
agent_result = AgentResult.from_agent_output(result.to_dict())
execution_result = agent_result.to_execution_result()

score = scorer.score(
    comparison=comparison,
    execution_result=execution_result,
    sql="SELECT name, age FROM users WHERE age > 26",
    dialect="sqlite",
    expected_results=expected,
)

print(f"Overall Score: {score.overall:.2%}")
print(f"Correctness: {score.correctness:.2%}")
print(f"Safety: {score.safety:.2%}")

executor.close()
```

### Example 2: Detect Hallucinations

```python
from agentx import SQLExecutor, ExecutorConfig

executor = SQLExecutor(ExecutorConfig(dialect="sqlite"))
executor.adapter.execute("CREATE TABLE products (id INT, name TEXT, price REAL)")
executor.refresh_schema()

# Query with phantom table
result = executor.process_query("SELECT * FROM fake_products")

print(f"Status: {result.overall_status}")  # FAILED
print(f"Errors: {result.validation['errors']}")
# ["Table 'fake_products' does not exist in schema"]

executor.close()
```

---

## Contributing

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Make your changes
4. Run tests (`python test_multi_dialect.py && python test_enhanced_scoring.py`)
5. Commit (`git commit -m 'Add amazing feature'`)
6. Push (`git push origin feature/amazing-feature`)
7. Open a Pull Request

---

## License

MIT License - see [LICENSE](LICENSE) for details.

---

## References

- [sqlglot Documentation](https://sqlglot.com/) - SQL parser and transpiler
- [DuckDB Documentation](https://duckdb.org/docs/) - In-process analytics database
- [Spider 2.0 Paper](https://arxiv.org/abs/2411.07763) - SQL benchmark reference
